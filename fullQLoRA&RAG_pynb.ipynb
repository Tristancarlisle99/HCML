{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm",
      "mount_file_id": "1mm7TsFS3ctDP4qQWx78ZdFy98prtaPKn",
      "authorship_tag": "ABX9TyN16Ltn+GxkLdziUL8L6UBx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "833a5650a2714753821648096f13d84f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_184c0dff6a2b4fcca094b2d85e26d50b",
              "IPY_MODEL_f10c6d877c0b474fb4aec948a2793e05",
              "IPY_MODEL_540434771ad64ef08a0b65538c63de11",
              "IPY_MODEL_b77e795204c74c48b651adef7e43d5e2",
              "IPY_MODEL_84df8c1b0c5a43cb8c0851abbd25b6d9"
            ],
            "layout": "IPY_MODEL_14160a34130a494ca8d68006a5082d98"
          }
        },
        "184c0dff6a2b4fcca094b2d85e26d50b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3dcabbe07b147f4af4a05c8d3c7fc4a",
            "placeholder": "​",
            "style": "IPY_MODEL_d142a96fbe5145b3aada858065e2ad99",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "f10c6d877c0b474fb4aec948a2793e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_9e013883b70e4a6796b806b75c2ef15f",
            "placeholder": "​",
            "style": "IPY_MODEL_44318003877c473ba9f38c5f4d823c59",
            "value": ""
          }
        },
        "540434771ad64ef08a0b65538c63de11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_bdab6cccc9704a5ebf95adbbbf31e802",
            "style": "IPY_MODEL_073bc809d91d4b009e2c257fd77d78bd",
            "value": true
          }
        },
        "b77e795204c74c48b651adef7e43d5e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_7b3accff004f42dc826386376386bbbc",
            "style": "IPY_MODEL_d0c01ee66ff741ae9ba93dfae4a0bd89",
            "tooltip": ""
          }
        },
        "84df8c1b0c5a43cb8c0851abbd25b6d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66841b602bad42a38257a6d56114e7f5",
            "placeholder": "​",
            "style": "IPY_MODEL_c5955eba8a4e4b939b70c1af447b03f9",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "14160a34130a494ca8d68006a5082d98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "c3dcabbe07b147f4af4a05c8d3c7fc4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d142a96fbe5145b3aada858065e2ad99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e013883b70e4a6796b806b75c2ef15f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44318003877c473ba9f38c5f4d823c59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdab6cccc9704a5ebf95adbbbf31e802": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "073bc809d91d4b009e2c257fd77d78bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b3accff004f42dc826386376386bbbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0c01ee66ff741ae9ba93dfae4a0bd89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "66841b602bad42a38257a6d56114e7f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5955eba8a4e4b939b70c1af447b03f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7801a0f8c6b45aabcc1370304fad4cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8e6e733c038410cb1d3edf924a177bc",
              "IPY_MODEL_de9abc6ed43f49e290dac3d3fd216433",
              "IPY_MODEL_45be154a91f74d2198f370177999dcf6"
            ],
            "layout": "IPY_MODEL_978676d5a76e427393bb58ef3cba7508"
          }
        },
        "b8e6e733c038410cb1d3edf924a177bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d79b09445b04ac1895999ce62bccbc3",
            "placeholder": "​",
            "style": "IPY_MODEL_913e47e3f3fb4bed83d16a4c46873645",
            "value": "config.json: 100%"
          }
        },
        "de9abc6ed43f49e290dac3d3fd216433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ae8b129582f4be3bc6e02f4cfa2f6f9",
            "max": 895,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf930936698c4675a9f8796b88df1d1a",
            "value": 895
          }
        },
        "45be154a91f74d2198f370177999dcf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f84efb0b033643d9a94b33c7c9571cd9",
            "placeholder": "​",
            "style": "IPY_MODEL_b7cc1bb6c2cd4311beb7b9b6eb96641b",
            "value": " 895/895 [00:00&lt;00:00, 65.1kB/s]"
          }
        },
        "978676d5a76e427393bb58ef3cba7508": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d79b09445b04ac1895999ce62bccbc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "913e47e3f3fb4bed83d16a4c46873645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ae8b129582f4be3bc6e02f4cfa2f6f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf930936698c4675a9f8796b88df1d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f84efb0b033643d9a94b33c7c9571cd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7cc1bb6c2cd4311beb7b9b6eb96641b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c6e2c597c5042efbe0572cf090dbf30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa0a99f8e48c4f5db603c2abcc357120",
              "IPY_MODEL_a0eb76aeaffa440a91db7fc111441a1e",
              "IPY_MODEL_d1dbb5cd23ea4d95bc368d7f3928b494"
            ],
            "layout": "IPY_MODEL_e675924a906c4810aca665b85818a90f"
          }
        },
        "fa0a99f8e48c4f5db603c2abcc357120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3468693a0134b3a83fb0e03f1b4ba55",
            "placeholder": "​",
            "style": "IPY_MODEL_9a04574043c54420afe38090d8c19a65",
            "value": "configuration_decilm.py: 100%"
          }
        },
        "a0eb76aeaffa440a91db7fc111441a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d558fed4b3484abf988dc6afca303205",
            "max": 576,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_373f59a2e9324b37bf0e8c6a91e34551",
            "value": 576
          }
        },
        "d1dbb5cd23ea4d95bc368d7f3928b494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d56476727bc04fa7ab8400bc9bc1351c",
            "placeholder": "​",
            "style": "IPY_MODEL_73ab55f409174c64b11150704ff6dba9",
            "value": " 576/576 [00:00&lt;00:00, 50.5kB/s]"
          }
        },
        "e675924a906c4810aca665b85818a90f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3468693a0134b3a83fb0e03f1b4ba55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a04574043c54420afe38090d8c19a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d558fed4b3484abf988dc6afca303205": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "373f59a2e9324b37bf0e8c6a91e34551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d56476727bc04fa7ab8400bc9bc1351c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73ab55f409174c64b11150704ff6dba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90e5fe58413549859fe97a4be93e2eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62726c3e96624e529b8024beded31816",
              "IPY_MODEL_c11f658c097b49ff918210dcfafe92b7",
              "IPY_MODEL_be8f62ea66104d41a59ffc084343071f"
            ],
            "layout": "IPY_MODEL_621e777e53ab4d9d839900f8c6a8a387"
          }
        },
        "62726c3e96624e529b8024beded31816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e6f99615122470e8c9d0a1a52cd4415",
            "placeholder": "​",
            "style": "IPY_MODEL_8c5112933fe84380b4c3ef0c32f64aa7",
            "value": "version_check.py: 100%"
          }
        },
        "c11f658c097b49ff918210dcfafe92b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_246ef997b1b64500a3e583d6564e417c",
            "max": 383,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d45d91575464b4c8af079d80cd3370e",
            "value": 383
          }
        },
        "be8f62ea66104d41a59ffc084343071f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa7ce7b572254d2ba8d0203ce76a6249",
            "placeholder": "​",
            "style": "IPY_MODEL_81e03e7141c345a3a621742bd18057e0",
            "value": " 383/383 [00:00&lt;00:00, 30.0kB/s]"
          }
        },
        "621e777e53ab4d9d839900f8c6a8a387": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e6f99615122470e8c9d0a1a52cd4415": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c5112933fe84380b4c3ef0c32f64aa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "246ef997b1b64500a3e583d6564e417c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d45d91575464b4c8af079d80cd3370e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa7ce7b572254d2ba8d0203ce76a6249": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81e03e7141c345a3a621742bd18057e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "998c69d5b6ff47978ad362e33717ba02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_becb63894e2b4f9fb96001a04818fd35",
              "IPY_MODEL_67cdf01447404c4aa396f4ff29567323",
              "IPY_MODEL_27272802ac634f63bbb63e783cf61a61"
            ],
            "layout": "IPY_MODEL_5d1b77645c5044d5a02bac9977bea033"
          }
        },
        "becb63894e2b4f9fb96001a04818fd35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c3aecd3155b44f295a4f947ec5d939a",
            "placeholder": "​",
            "style": "IPY_MODEL_e74e98fd7dc0443da83a0e5d46f8b8bf",
            "value": "(…)sformers_v4_35_2__configuration_llama.py: 100%"
          }
        },
        "67cdf01447404c4aa396f4ff29567323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3c7d83e08ff4761bbbc80638d05f679",
            "max": 9195,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ee1d38afce14bf58b88b00bfde5f151",
            "value": 9195
          }
        },
        "27272802ac634f63bbb63e783cf61a61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a67e8837bf0542ffa15c78f1694d1c16",
            "placeholder": "​",
            "style": "IPY_MODEL_0996ae2c89b34a189fa9112654a13a36",
            "value": " 9.20k/9.20k [00:00&lt;00:00, 903kB/s]"
          }
        },
        "5d1b77645c5044d5a02bac9977bea033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c3aecd3155b44f295a4f947ec5d939a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e74e98fd7dc0443da83a0e5d46f8b8bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3c7d83e08ff4761bbbc80638d05f679": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ee1d38afce14bf58b88b00bfde5f151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a67e8837bf0542ffa15c78f1694d1c16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0996ae2c89b34a189fa9112654a13a36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f667bd470484bfab2a5173209803971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef90535cc60a4a06b7d7dc47d12ab7f0",
              "IPY_MODEL_74e90e6f73a94bae80695a59ed02e484",
              "IPY_MODEL_25c81ff7a66c4dee8feac343447c100d"
            ],
            "layout": "IPY_MODEL_a91d0cd8a9834150915e15b268f2949f"
          }
        },
        "ef90535cc60a4a06b7d7dc47d12ab7f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22bff245c74c4d6b845eb93fbab16201",
            "placeholder": "​",
            "style": "IPY_MODEL_feb0da1ec1f6453fa15a15fe0d2f9412",
            "value": "modeling_decilm.py: 100%"
          }
        },
        "74e90e6f73a94bae80695a59ed02e484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bee8c8bfb6b34ed490fb4d636b2aef82",
            "max": 14456,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd60bfc9156b4640bcb077ff08dcbeba",
            "value": 14456
          }
        },
        "25c81ff7a66c4dee8feac343447c100d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_432c027061fa42f8b8c5299640347874",
            "placeholder": "​",
            "style": "IPY_MODEL_92a933451c50485cb6e5e7b8ac7dbb36",
            "value": " 14.5k/14.5k [00:00&lt;00:00, 1.19MB/s]"
          }
        },
        "a91d0cd8a9834150915e15b268f2949f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22bff245c74c4d6b845eb93fbab16201": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feb0da1ec1f6453fa15a15fe0d2f9412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bee8c8bfb6b34ed490fb4d636b2aef82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd60bfc9156b4640bcb077ff08dcbeba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "432c027061fa42f8b8c5299640347874": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92a933451c50485cb6e5e7b8ac7dbb36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25e3ec78768f4c24b4805a310b765b8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03268f066f434f33bc42c2538cbd2117",
              "IPY_MODEL_b90c40ea94ca41478822446c1ad6b4ad",
              "IPY_MODEL_d35104ac5eb5422bad15e8093f96503a"
            ],
            "layout": "IPY_MODEL_e4da50dac5734e368b0cd952d0bef65e"
          }
        },
        "03268f066f434f33bc42c2538cbd2117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5672050458ab4e05b529cdfde54df355",
            "placeholder": "​",
            "style": "IPY_MODEL_75f7ae89dfb041919eb9bbeea935f5a2",
            "value": "(…)ers_v4_35_2__modeling_attn_mask_utils.py: 100%"
          }
        },
        "b90c40ea94ca41478822446c1ad6b4ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbbe736a203244d792ea8a0d799e57eb",
            "max": 10122,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5fc56b1a523e4ca3b126104f9d4a5aa4",
            "value": 10122
          }
        },
        "d35104ac5eb5422bad15e8093f96503a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57e174557e864c4bb5ebe5d59fa9d9f3",
            "placeholder": "​",
            "style": "IPY_MODEL_ce3c1168a0424f4481d82508625056bc",
            "value": " 10.1k/10.1k [00:00&lt;00:00, 751kB/s]"
          }
        },
        "e4da50dac5734e368b0cd952d0bef65e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5672050458ab4e05b529cdfde54df355": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75f7ae89dfb041919eb9bbeea935f5a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbbe736a203244d792ea8a0d799e57eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fc56b1a523e4ca3b126104f9d4a5aa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57e174557e864c4bb5ebe5d59fa9d9f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce3c1168a0424f4481d82508625056bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "931b01da7b624c1e83c30d668c72dac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4495f65f8b4d4cabb1cd87862ba9edef",
              "IPY_MODEL_f0e5c5e8801243e59ab547afffae162c",
              "IPY_MODEL_beaca56541ef4205a85b63a81a301315"
            ],
            "layout": "IPY_MODEL_a4499448aee0404f810af2ad962a9bae"
          }
        },
        "4495f65f8b4d4cabb1cd87862ba9edef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcf20e36d272433c9592a00278c55cfd",
            "placeholder": "​",
            "style": "IPY_MODEL_dcc80ed7da8a4af389d1b251530cfaa2",
            "value": "transformers_v4_35_2__modeling_llama.py: 100%"
          }
        },
        "f0e5c5e8801243e59ab547afffae162c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_163c72ed8a4e4a42a5fc29a3290bcd14",
            "max": 56426,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ef0b2d19cd7480e925d3a42f1568e5d",
            "value": 56426
          }
        },
        "beaca56541ef4205a85b63a81a301315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7a5b3f118e0414ba7752f9d2d8c3acf",
            "placeholder": "​",
            "style": "IPY_MODEL_24303f47b20545eb93540458487d8fd7",
            "value": " 56.4k/56.4k [00:00&lt;00:00, 703kB/s]"
          }
        },
        "a4499448aee0404f810af2ad962a9bae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcf20e36d272433c9592a00278c55cfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcc80ed7da8a4af389d1b251530cfaa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "163c72ed8a4e4a42a5fc29a3290bcd14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ef0b2d19cd7480e925d3a42f1568e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7a5b3f118e0414ba7752f9d2d8c3acf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24303f47b20545eb93540458487d8fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ce276aff0e9494bac328a24bf19162a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47ece66d22bc4690b8af9f8941cde1a4",
              "IPY_MODEL_baa22563affe49269c8b0529642c3b76",
              "IPY_MODEL_e644618a2b3e4889b2be0dbe8c7f5edb"
            ],
            "layout": "IPY_MODEL_62496961e9394ce0818a8e30802a5eef"
          }
        },
        "47ece66d22bc4690b8af9f8941cde1a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69be5aba9ff7421b8ff460536d10c0cb",
            "placeholder": "​",
            "style": "IPY_MODEL_e8b25a0bc95149648449c3991c42bb94",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "baa22563affe49269c8b0529642c3b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_465433a14ac04c2db7fae313830b9fbc",
            "max": 23950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8fd24c38fdf0459580ebe76285f695ac",
            "value": 23950
          }
        },
        "e644618a2b3e4889b2be0dbe8c7f5edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a6b680c4c424f06be473f8db5c9ff9c",
            "placeholder": "​",
            "style": "IPY_MODEL_7f041d45543b45778e6b573c2881d59d",
            "value": " 23.9k/23.9k [00:00&lt;00:00, 2.01MB/s]"
          }
        },
        "62496961e9394ce0818a8e30802a5eef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69be5aba9ff7421b8ff460536d10c0cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8b25a0bc95149648449c3991c42bb94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "465433a14ac04c2db7fae313830b9fbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fd24c38fdf0459580ebe76285f695ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a6b680c4c424f06be473f8db5c9ff9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f041d45543b45778e6b573c2881d59d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ca7653f6c3948e5b6ef8d22523a1248": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c74908c05c784cc788916fb3e0125c53",
              "IPY_MODEL_8a377a361ff6484ba165ff6eabcef45f",
              "IPY_MODEL_1a79fe64d12a42848dfd20479cfd464c"
            ],
            "layout": "IPY_MODEL_c8ded981909f4000b6c7b95c2b9aa09e"
          }
        },
        "c74908c05c784cc788916fb3e0125c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf84f6675c4a43d2b2dd542956a1c478",
            "placeholder": "​",
            "style": "IPY_MODEL_a57a849c07814324aa0fd43fb42c36d0",
            "value": "Downloading shards: 100%"
          }
        },
        "8a377a361ff6484ba165ff6eabcef45f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c646841638a45748dbdf233f36d04f2",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11948e50af8d4bb39405aa0a6595081d",
            "value": 3
          }
        },
        "1a79fe64d12a42848dfd20479cfd464c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c759fe309edd4178b3e4afa49f11552c",
            "placeholder": "​",
            "style": "IPY_MODEL_525faa561548477487d2793ed23553c4",
            "value": " 3/3 [04:37&lt;00:00, 87.59s/it]"
          }
        },
        "c8ded981909f4000b6c7b95c2b9aa09e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf84f6675c4a43d2b2dd542956a1c478": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a57a849c07814324aa0fd43fb42c36d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c646841638a45748dbdf233f36d04f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11948e50af8d4bb39405aa0a6595081d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c759fe309edd4178b3e4afa49f11552c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "525faa561548477487d2793ed23553c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "721f9a9f783f42c48fb26efe45791ef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e45bf0b54f844953896ce175463eb98c",
              "IPY_MODEL_35ee881fcf8640dda6b5b34c050f5e85",
              "IPY_MODEL_f4d81b3e3bd84b6ab546b008fe839f1e"
            ],
            "layout": "IPY_MODEL_e9999ff49bf9403a86ce0b5c8c5112cb"
          }
        },
        "e45bf0b54f844953896ce175463eb98c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c003d2d7d9804cd58e84c3fb2a145897",
            "placeholder": "​",
            "style": "IPY_MODEL_85abb4d0f7b24780b94428e2c1ca66fb",
            "value": "model-00001-of-00003.safetensors: 100%"
          }
        },
        "35ee881fcf8640dda6b5b34c050f5e85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f365010cf00d420a9f66f5440461c312",
            "max": 4985122440,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76e225910f5f4671ac8fda0c491b4eee",
            "value": 4985122440
          }
        },
        "f4d81b3e3bd84b6ab546b008fe839f1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_398137a70a354f89b032110e4b639814",
            "placeholder": "​",
            "style": "IPY_MODEL_baada4fe31384a89aeb6984b4e777d8b",
            "value": " 4.99G/4.99G [01:56&lt;00:00, 57.7MB/s]"
          }
        },
        "e9999ff49bf9403a86ce0b5c8c5112cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c003d2d7d9804cd58e84c3fb2a145897": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85abb4d0f7b24780b94428e2c1ca66fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f365010cf00d420a9f66f5440461c312": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76e225910f5f4671ac8fda0c491b4eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "398137a70a354f89b032110e4b639814": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baada4fe31384a89aeb6984b4e777d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7953b272b3d4203b739a2cbc8b6ac8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aab2b39505ef4fb9964d0beb6baa0e3d",
              "IPY_MODEL_256a8947793346139367e238d6f038c8",
              "IPY_MODEL_e001141d2a6c44838459a063113a51dd"
            ],
            "layout": "IPY_MODEL_90eb395decd14895a42f2294db4242fa"
          }
        },
        "aab2b39505ef4fb9964d0beb6baa0e3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2973bf311b2478c911691e967deaf0b",
            "placeholder": "​",
            "style": "IPY_MODEL_5a63fd5fd87947369649be01e6ce116c",
            "value": "model-00002-of-00003.safetensors: 100%"
          }
        },
        "256a8947793346139367e238d6f038c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d06a4b71b3d410ca8b4b7f80658df31",
            "max": 4922207848,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b7ee286f2b3499f9dc983f62940650c",
            "value": 4922207848
          }
        },
        "e001141d2a6c44838459a063113a51dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3a1658adc0f4857b81ef8facabdd1f4",
            "placeholder": "​",
            "style": "IPY_MODEL_b8ad8990c66e4b489fa8b609a6d50be7",
            "value": " 4.92G/4.92G [01:26&lt;00:00, 57.9MB/s]"
          }
        },
        "90eb395decd14895a42f2294db4242fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2973bf311b2478c911691e967deaf0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a63fd5fd87947369649be01e6ce116c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d06a4b71b3d410ca8b4b7f80658df31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b7ee286f2b3499f9dc983f62940650c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3a1658adc0f4857b81ef8facabdd1f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8ad8990c66e4b489fa8b609a6d50be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9d365de116e40f5a78506606d650924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3cf3373d1d62447ebb80de30797427fb",
              "IPY_MODEL_dc21eba67a1442438e8239934cbb6559",
              "IPY_MODEL_c921e107a3dc4562a3ab12e1eab96483"
            ],
            "layout": "IPY_MODEL_f7d9b73a597b45659fdde9b048ce6a9d"
          }
        },
        "3cf3373d1d62447ebb80de30797427fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cab85fbe503d47929b37f77c360de790",
            "placeholder": "​",
            "style": "IPY_MODEL_ec2570ece56f415f8305a72c482c1209",
            "value": "model-00003-of-00003.safetensors: 100%"
          }
        },
        "dc21eba67a1442438e8239934cbb6559": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfa00ccbafc4416d96032d01e92fe47d",
            "max": 4179805944,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_142a3e01dd174efd807fc8592ce6df0d",
            "value": 4179805944
          }
        },
        "c921e107a3dc4562a3ab12e1eab96483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc1a85fb3f394d7ba008083393035dd5",
            "placeholder": "​",
            "style": "IPY_MODEL_efe1011d4d204a4d8b5667b55b8ea789",
            "value": " 4.18G/4.18G [01:13&lt;00:00, 56.8MB/s]"
          }
        },
        "f7d9b73a597b45659fdde9b048ce6a9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cab85fbe503d47929b37f77c360de790": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec2570ece56f415f8305a72c482c1209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfa00ccbafc4416d96032d01e92fe47d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "142a3e01dd174efd807fc8592ce6df0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc1a85fb3f394d7ba008083393035dd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efe1011d4d204a4d8b5667b55b8ea789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e068e7c31444474d89b8f99f0d834435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52951534a74d46159fe6b948867abc1d",
              "IPY_MODEL_4342daab1a03414a991e5916467c400e",
              "IPY_MODEL_688a56f1dae942039db3267ecc7dad30"
            ],
            "layout": "IPY_MODEL_10dcdb326934489e9fa609d4d5e0e721"
          }
        },
        "52951534a74d46159fe6b948867abc1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b23812a35af4f7081578b723d3e7495",
            "placeholder": "​",
            "style": "IPY_MODEL_8c3a79e4cc3c4cbbb4720c9d6805ac68",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "4342daab1a03414a991e5916467c400e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0df9b252174f41609f7ca7a0b01ac7a0",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b18bbf25ceb947f69c9b80d94d9f3a40",
            "value": 3
          }
        },
        "688a56f1dae942039db3267ecc7dad30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc57a32abcc4428dadb1cf7aad54682d",
            "placeholder": "​",
            "style": "IPY_MODEL_349a1225967b4928b4bb3069acc4805b",
            "value": " 3/3 [00:08&lt;00:00,  2.83s/it]"
          }
        },
        "10dcdb326934489e9fa609d4d5e0e721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b23812a35af4f7081578b723d3e7495": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c3a79e4cc3c4cbbb4720c9d6805ac68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0df9b252174f41609f7ca7a0b01ac7a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b18bbf25ceb947f69c9b80d94d9f3a40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc57a32abcc4428dadb1cf7aad54682d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "349a1225967b4928b4bb3069acc4805b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "debabdc0460d4ae9bbe4bffd4d90af55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c5f791949f74dbbb48624a6cdc96ee6",
              "IPY_MODEL_6137120f84d643cd831967d09e9398f5",
              "IPY_MODEL_6a0951c02d1641048de2a1f94def73ca"
            ],
            "layout": "IPY_MODEL_f9d33f3b11034f73ae7d1b438d7ce47b"
          }
        },
        "2c5f791949f74dbbb48624a6cdc96ee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02ca2f5e5c0240c3ad588bf62e86b624",
            "placeholder": "​",
            "style": "IPY_MODEL_8d22e28ec9664f6cbadbc15b4a780f5a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "6137120f84d643cd831967d09e9398f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f1733194a784cbda82dd8bc4a59cece",
            "max": 1329,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53acf1d4cc86425f9fb7e85c5e425f37",
            "value": 1329
          }
        },
        "6a0951c02d1641048de2a1f94def73ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbc1d8c7d8694b67970fd4ae02199c3a",
            "placeholder": "​",
            "style": "IPY_MODEL_0f12d26d122840e98f1d98539a828b14",
            "value": " 1.33k/1.33k [00:00&lt;00:00, 116kB/s]"
          }
        },
        "f9d33f3b11034f73ae7d1b438d7ce47b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02ca2f5e5c0240c3ad588bf62e86b624": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d22e28ec9664f6cbadbc15b4a780f5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f1733194a784cbda82dd8bc4a59cece": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53acf1d4cc86425f9fb7e85c5e425f37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cbc1d8c7d8694b67970fd4ae02199c3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f12d26d122840e98f1d98539a828b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5763c37ef1064c16a30644a821cbba8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8db0c9e36c35471d9a363a3655227c9a",
              "IPY_MODEL_3fa81b4fc62c4f13b2db9a41af464130",
              "IPY_MODEL_fd4e0b932d8f49ef926524a8a05ef082"
            ],
            "layout": "IPY_MODEL_af024457dc64458fbef3fe70976e91a0"
          }
        },
        "8db0c9e36c35471d9a363a3655227c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8711b5d78b154183b800b530d9276ccd",
            "placeholder": "​",
            "style": "IPY_MODEL_e7d12a1b370e4e9d8a17436c5a4dea98",
            "value": "tokenizer.model: 100%"
          }
        },
        "3fa81b4fc62c4f13b2db9a41af464130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba34e92d010d45a9b46d7b5ff146a091",
            "max": 493443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db9cff6ec9804eccbb8d6cc8db0aae2b",
            "value": 493443
          }
        },
        "fd4e0b932d8f49ef926524a8a05ef082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff24724d15c24e66857de05b1485117b",
            "placeholder": "​",
            "style": "IPY_MODEL_0bad6a611e334c2cbd1eb0e79da91f31",
            "value": " 493k/493k [00:00&lt;00:00, 32.4MB/s]"
          }
        },
        "af024457dc64458fbef3fe70976e91a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8711b5d78b154183b800b530d9276ccd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7d12a1b370e4e9d8a17436c5a4dea98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba34e92d010d45a9b46d7b5ff146a091": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db9cff6ec9804eccbb8d6cc8db0aae2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff24724d15c24e66857de05b1485117b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bad6a611e334c2cbd1eb0e79da91f31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34baf4d85c2342108bfc0cf2b2cb115e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8dc1362f74914ea0b519c7d27022854d",
              "IPY_MODEL_2295e0a005ac4141a9ac2d2d3f2c97e8",
              "IPY_MODEL_c7b9b77eb15e47f6b982127bbe6790db"
            ],
            "layout": "IPY_MODEL_f11b5b00ad7b4486b05b783ee95b1aac"
          }
        },
        "8dc1362f74914ea0b519c7d27022854d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9cc20ba0d4b4fcaa20bced98affc063",
            "placeholder": "​",
            "style": "IPY_MODEL_4f9a55d0960a423ebec6e52d19ccc755",
            "value": "tokenizer.json: 100%"
          }
        },
        "2295e0a005ac4141a9ac2d2d3f2c97e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e973b6230c55410dbce6ed3e9074aa32",
            "max": 1795303,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71d86549ddee4d9a81196150c0ad5625",
            "value": 1795303
          }
        },
        "c7b9b77eb15e47f6b982127bbe6790db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_713d88ac8aad4a83883b8a3eae583125",
            "placeholder": "​",
            "style": "IPY_MODEL_ea7535b51e114fe2929fc2021100ac12",
            "value": " 1.80M/1.80M [00:00&lt;00:00, 4.40MB/s]"
          }
        },
        "f11b5b00ad7b4486b05b783ee95b1aac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9cc20ba0d4b4fcaa20bced98affc063": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f9a55d0960a423ebec6e52d19ccc755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e973b6230c55410dbce6ed3e9074aa32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71d86549ddee4d9a81196150c0ad5625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "713d88ac8aad4a83883b8a3eae583125": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea7535b51e114fe2929fc2021100ac12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7e585622b9b418cb5f9723a33f6d200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1f3e0354362457ebd9270e6dbd61484",
              "IPY_MODEL_04e74c421f434636b623cc0078f6764e",
              "IPY_MODEL_1afe8dea704740ad8d2b7df293a607d1"
            ],
            "layout": "IPY_MODEL_deca638442f845009ac07d9349ca6117"
          }
        },
        "d1f3e0354362457ebd9270e6dbd61484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01d5c407d9024506a21aca5662988e37",
            "placeholder": "​",
            "style": "IPY_MODEL_63b4e7b430fc4477bffc54e4166d30aa",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "04e74c421f434636b623cc0078f6764e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d51480b6926944ffb968a5ea2bf6ceab",
            "max": 414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9d9e8af200c41fbbc49dc9421527e7b",
            "value": 414
          }
        },
        "1afe8dea704740ad8d2b7df293a607d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_463ed660110446b69171eb1789988d1d",
            "placeholder": "​",
            "style": "IPY_MODEL_e3fd8f5e1469464c803c4a0d129b3277",
            "value": " 414/414 [00:00&lt;00:00, 37.5kB/s]"
          }
        },
        "deca638442f845009ac07d9349ca6117": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01d5c407d9024506a21aca5662988e37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63b4e7b430fc4477bffc54e4166d30aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d51480b6926944ffb968a5ea2bf6ceab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9d9e8af200c41fbbc49dc9421527e7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "463ed660110446b69171eb1789988d1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3fd8f5e1469464c803c4a0d129b3277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5561bf758c646e29744240230116be3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d7ad2c01e084e2aae35717959a41398",
              "IPY_MODEL_f899447a560048e48975fdb16fa46e91",
              "IPY_MODEL_945855dea50742cebec32a038db1c800"
            ],
            "layout": "IPY_MODEL_fdf052c28e384514bfeb8f0959e0a2b4"
          }
        },
        "1d7ad2c01e084e2aae35717959a41398": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c17f6a9aac44314be13b08c14833a58",
            "placeholder": "​",
            "style": "IPY_MODEL_08933fef8dc7421f88b746448e1c1775",
            "value": "Generating train split: "
          }
        },
        "f899447a560048e48975fdb16fa46e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a907572a3abc4fb295d5d69bd0d95090",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c291dfac9723479095e0cac42b089cdd",
            "value": 1
          }
        },
        "945855dea50742cebec32a038db1c800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8ccbc3f45a34ecf8917a608f85340d9",
            "placeholder": "​",
            "style": "IPY_MODEL_6a8c3502b9084e4c9d428c9da095ae4b",
            "value": " 21386/0 [00:00&lt;00:00, 20240.37 examples/s]"
          }
        },
        "fdf052c28e384514bfeb8f0959e0a2b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c17f6a9aac44314be13b08c14833a58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08933fef8dc7421f88b746448e1c1775": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a907572a3abc4fb295d5d69bd0d95090": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c291dfac9723479095e0cac42b089cdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8ccbc3f45a34ecf8917a608f85340d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a8c3502b9084e4c9d428c9da095ae4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14e84ab3b0a4493c8f56d699ca16770e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a9cd6313c9c343cdac2bd580e0974730",
              "IPY_MODEL_804b5c1ebd344883a6643f6cf763b090",
              "IPY_MODEL_e1e061cf1e3f479d97bf97d6e65366c5"
            ],
            "layout": "IPY_MODEL_effae7cfe84f4d07882b1c7025c081fc"
          }
        },
        "a9cd6313c9c343cdac2bd580e0974730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cded81d9bbc4ce8b01d24663c157135",
            "placeholder": "​",
            "style": "IPY_MODEL_4258032f1e264cf085d681dfe96c61d0",
            "value": "Map: 100%"
          }
        },
        "804b5c1ebd344883a6643f6cf763b090": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e30c1ce08b024e369859421aa8241737",
            "max": 19247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d64b891d7568434bb6c1a7eee2ad4434",
            "value": 19247
          }
        },
        "e1e061cf1e3f479d97bf97d6e65366c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7557f91f250468ab0229a371dd9bc3c",
            "placeholder": "​",
            "style": "IPY_MODEL_c55ce0ea4dda4623ba67097db824d8c5",
            "value": " 19247/19247 [00:01&lt;00:00, 9717.20 examples/s]"
          }
        },
        "effae7cfe84f4d07882b1c7025c081fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cded81d9bbc4ce8b01d24663c157135": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4258032f1e264cf085d681dfe96c61d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e30c1ce08b024e369859421aa8241737": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d64b891d7568434bb6c1a7eee2ad4434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7557f91f250468ab0229a371dd9bc3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c55ce0ea4dda4623ba67097db824d8c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59b0f71ba2fc40bb9f9e0682edbab9e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81444bf8509047909910822c2d1422cf",
              "IPY_MODEL_48a9d661d61a420d9e67ad1e276f92de",
              "IPY_MODEL_f8fc988f7ed449a49ba6fdb1d6b9037f"
            ],
            "layout": "IPY_MODEL_50d3c7df599f4af186ba6e9ee18ef8f4"
          }
        },
        "81444bf8509047909910822c2d1422cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c660735e1299436aa956370ef3e3c097",
            "placeholder": "​",
            "style": "IPY_MODEL_93797e090bb544c49144d0eb145d3f62",
            "value": "Map: 100%"
          }
        },
        "48a9d661d61a420d9e67ad1e276f92de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cff969f4340410f894eb8e182b433fc",
            "max": 2139,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5da9a41e1f1e4122bd0b9add17bd8161",
            "value": 2139
          }
        },
        "f8fc988f7ed449a49ba6fdb1d6b9037f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8377d56d2a8468d84a0804d02dc7382",
            "placeholder": "​",
            "style": "IPY_MODEL_43ea176abe37485ba44adc7475e21e04",
            "value": " 2139/2139 [00:00&lt;00:00, 9394.33 examples/s]"
          }
        },
        "50d3c7df599f4af186ba6e9ee18ef8f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c660735e1299436aa956370ef3e3c097": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93797e090bb544c49144d0eb145d3f62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cff969f4340410f894eb8e182b433fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5da9a41e1f1e4122bd0b9add17bd8161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8377d56d2a8468d84a0804d02dc7382": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43ea176abe37485ba44adc7475e21e04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "825f3b6c603a4354aafdb7e95edbea77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1fd3b4ddbfc4a98ae6433b5c1e85c5a",
              "IPY_MODEL_44e085c417164432be6677d5e960cae1",
              "IPY_MODEL_d466a93ed09e4ff48ec57929cb4610ef"
            ],
            "layout": "IPY_MODEL_8b8e9cda9ffd4477be350e1da0a4c750"
          }
        },
        "e1fd3b4ddbfc4a98ae6433b5c1e85c5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46090990ac3046b3b193c5c5400f9952",
            "placeholder": "​",
            "style": "IPY_MODEL_579a14aed0c7455098180d3ce8786131",
            "value": "Map (num_proc=8): 100%"
          }
        },
        "44e085c417164432be6677d5e960cae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05b65c58492449c9812dc3386497aa71",
            "max": 19247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f29d8d0f8cf24a40baffcabee56bb9c2",
            "value": 19247
          }
        },
        "d466a93ed09e4ff48ec57929cb4610ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_431784b7fb3f4dc2b22d182b81e0785e",
            "placeholder": "​",
            "style": "IPY_MODEL_0f43f4cf4497498fa6ff9f42e810d1e5",
            "value": " 19247/19247 [00:01&lt;00:00, 18603.22 examples/s]"
          }
        },
        "8b8e9cda9ffd4477be350e1da0a4c750": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46090990ac3046b3b193c5c5400f9952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "579a14aed0c7455098180d3ce8786131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05b65c58492449c9812dc3386497aa71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f29d8d0f8cf24a40baffcabee56bb9c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "431784b7fb3f4dc2b22d182b81e0785e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f43f4cf4497498fa6ff9f42e810d1e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c99f2117cfe8431497ca23936f40e9aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce6e57351b25474795e372f524ba418f",
              "IPY_MODEL_5ecfd83a338842c6b2c6afe4c13d8b11",
              "IPY_MODEL_20743cc02cf54d809ec9d88c8630afde"
            ],
            "layout": "IPY_MODEL_cfcfbfa797ba4ac3afdc29b65a23aa4c"
          }
        },
        "ce6e57351b25474795e372f524ba418f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3be65f01365b46d9ab56bd984352d596",
            "placeholder": "​",
            "style": "IPY_MODEL_6c6df6e9f35f4994a011b875f53da444",
            "value": "Map (num_proc=8): 100%"
          }
        },
        "5ecfd83a338842c6b2c6afe4c13d8b11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1a86edd9cd04afbaa64aadc26a7a6ed",
            "max": 2139,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d82e8cf634704036980deedbc9c3ce3b",
            "value": 2139
          }
        },
        "20743cc02cf54d809ec9d88c8630afde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e421d04415941638873cc624e7cefaa",
            "placeholder": "​",
            "style": "IPY_MODEL_682a96a8a4524a3789e9b2d53da90dfb",
            "value": " 2139/2139 [00:00&lt;00:00, 3215.69 examples/s]"
          }
        },
        "cfcfbfa797ba4ac3afdc29b65a23aa4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3be65f01365b46d9ab56bd984352d596": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c6df6e9f35f4994a011b875f53da444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1a86edd9cd04afbaa64aadc26a7a6ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d82e8cf634704036980deedbc9c3ce3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e421d04415941638873cc624e7cefaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "682a96a8a4524a3789e9b2d53da90dfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tristancarlisle99/HCML/blob/main/fullQLoRA%26RAG_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Setup"
      ],
      "metadata": {
        "id": "ffwXQ-iWOJuG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VigNcN-HDbaZ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install peft\n",
        "!pip install huggingface_hub\n",
        "!pip install transformers\n",
        "!pip install accelerate\n",
        "!pip install bitsandbytes\n",
        "!pip install -q -U trl\n",
        "!pip install ninja"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
        "from pathlib import Path\n",
        "from typing import Optional\n",
        "from trl import SFTTrainer\n",
        "import os"
      ],
      "metadata": {
        "id": "qM_p4lTGXXj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "833a5650a2714753821648096f13d84f",
            "184c0dff6a2b4fcca094b2d85e26d50b",
            "f10c6d877c0b474fb4aec948a2793e05",
            "540434771ad64ef08a0b65538c63de11",
            "b77e795204c74c48b651adef7e43d5e2",
            "84df8c1b0c5a43cb8c0851abbd25b6d9",
            "14160a34130a494ca8d68006a5082d98",
            "c3dcabbe07b147f4af4a05c8d3c7fc4a",
            "d142a96fbe5145b3aada858065e2ad99",
            "9e013883b70e4a6796b806b75c2ef15f",
            "44318003877c473ba9f38c5f4d823c59",
            "bdab6cccc9704a5ebf95adbbbf31e802",
            "073bc809d91d4b009e2c257fd77d78bd",
            "7b3accff004f42dc826386376386bbbc",
            "d0c01ee66ff741ae9ba93dfae4a0bd89",
            "66841b602bad42a38257a6d56114e7f5",
            "c5955eba8a4e4b939b70c1af447b03f9"
          ]
        },
        "id": "dyed-zQyOR4-",
        "outputId": "a04cfcfd-67d5-4f30-fccd-3f8f57b32313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "833a5650a2714753821648096f13d84f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Down Stream task directory set up\n",
        "\n"
      ],
      "metadata": {
        "id": "qdw8MQoYN_QP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Downstream_task_checkpoint_directories(path: Optional[Path]= None, dir_name: str=\"LoRAs\"):\n",
        "  current_dir = path if path is not None else Path('./')\n",
        "  output_dir = current_dir / dir_name\n",
        "  output_dir.mkdir(parents=True, exist_ok=True)\n",
        "  return output_dir"
      ],
      "metadata": {
        "id": "MbfMiCj4LmWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DeciLora = Downstream_task_checkpoint_directories(dir_name=\"DeciLora_finetuned_checkpoints\")\n",
        "print(f\"Output directory created: {DeciLora}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHYgM3sFMkmW",
        "outputId": "6c37a27d-ed3f-46f5-e731-74c44871a131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output directory created: DeciLora_finetuned_checkpoints\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quantization config - 4 bit and The matrix multiplication and training will be faster if one uses a 16-bit compute dtype\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DJCMHuvBNcJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit = True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16)"
      ],
      "metadata": {
        "id": "KwYNCxeJNbFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model selection and set up"
      ],
      "metadata": {
        "id": "gsgfUgo0NoBA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-jOIrGY7ygaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = 'Deci/DeciLM-7B'\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
        "                                             device_map=\"auto\",\n",
        "                                             trust_remote_code=True,\n",
        "                                             quantization_config=bnb_config\n",
        "                                             )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "a7801a0f8c6b45aabcc1370304fad4cd",
            "b8e6e733c038410cb1d3edf924a177bc",
            "de9abc6ed43f49e290dac3d3fd216433",
            "45be154a91f74d2198f370177999dcf6",
            "978676d5a76e427393bb58ef3cba7508",
            "7d79b09445b04ac1895999ce62bccbc3",
            "913e47e3f3fb4bed83d16a4c46873645",
            "0ae8b129582f4be3bc6e02f4cfa2f6f9",
            "cf930936698c4675a9f8796b88df1d1a",
            "f84efb0b033643d9a94b33c7c9571cd9",
            "b7cc1bb6c2cd4311beb7b9b6eb96641b",
            "3c6e2c597c5042efbe0572cf090dbf30",
            "fa0a99f8e48c4f5db603c2abcc357120",
            "a0eb76aeaffa440a91db7fc111441a1e",
            "d1dbb5cd23ea4d95bc368d7f3928b494",
            "e675924a906c4810aca665b85818a90f",
            "d3468693a0134b3a83fb0e03f1b4ba55",
            "9a04574043c54420afe38090d8c19a65",
            "d558fed4b3484abf988dc6afca303205",
            "373f59a2e9324b37bf0e8c6a91e34551",
            "d56476727bc04fa7ab8400bc9bc1351c",
            "73ab55f409174c64b11150704ff6dba9",
            "90e5fe58413549859fe97a4be93e2eb6",
            "62726c3e96624e529b8024beded31816",
            "c11f658c097b49ff918210dcfafe92b7",
            "be8f62ea66104d41a59ffc084343071f",
            "621e777e53ab4d9d839900f8c6a8a387",
            "3e6f99615122470e8c9d0a1a52cd4415",
            "8c5112933fe84380b4c3ef0c32f64aa7",
            "246ef997b1b64500a3e583d6564e417c",
            "1d45d91575464b4c8af079d80cd3370e",
            "aa7ce7b572254d2ba8d0203ce76a6249",
            "81e03e7141c345a3a621742bd18057e0",
            "998c69d5b6ff47978ad362e33717ba02",
            "becb63894e2b4f9fb96001a04818fd35",
            "67cdf01447404c4aa396f4ff29567323",
            "27272802ac634f63bbb63e783cf61a61",
            "5d1b77645c5044d5a02bac9977bea033",
            "2c3aecd3155b44f295a4f947ec5d939a",
            "e74e98fd7dc0443da83a0e5d46f8b8bf",
            "d3c7d83e08ff4761bbbc80638d05f679",
            "0ee1d38afce14bf58b88b00bfde5f151",
            "a67e8837bf0542ffa15c78f1694d1c16",
            "0996ae2c89b34a189fa9112654a13a36",
            "4f667bd470484bfab2a5173209803971",
            "ef90535cc60a4a06b7d7dc47d12ab7f0",
            "74e90e6f73a94bae80695a59ed02e484",
            "25c81ff7a66c4dee8feac343447c100d",
            "a91d0cd8a9834150915e15b268f2949f",
            "22bff245c74c4d6b845eb93fbab16201",
            "feb0da1ec1f6453fa15a15fe0d2f9412",
            "bee8c8bfb6b34ed490fb4d636b2aef82",
            "fd60bfc9156b4640bcb077ff08dcbeba",
            "432c027061fa42f8b8c5299640347874",
            "92a933451c50485cb6e5e7b8ac7dbb36",
            "25e3ec78768f4c24b4805a310b765b8c",
            "03268f066f434f33bc42c2538cbd2117",
            "b90c40ea94ca41478822446c1ad6b4ad",
            "d35104ac5eb5422bad15e8093f96503a",
            "e4da50dac5734e368b0cd952d0bef65e",
            "5672050458ab4e05b529cdfde54df355",
            "75f7ae89dfb041919eb9bbeea935f5a2",
            "bbbe736a203244d792ea8a0d799e57eb",
            "5fc56b1a523e4ca3b126104f9d4a5aa4",
            "57e174557e864c4bb5ebe5d59fa9d9f3",
            "ce3c1168a0424f4481d82508625056bc",
            "931b01da7b624c1e83c30d668c72dac4",
            "4495f65f8b4d4cabb1cd87862ba9edef",
            "f0e5c5e8801243e59ab547afffae162c",
            "beaca56541ef4205a85b63a81a301315",
            "a4499448aee0404f810af2ad962a9bae",
            "fcf20e36d272433c9592a00278c55cfd",
            "dcc80ed7da8a4af389d1b251530cfaa2",
            "163c72ed8a4e4a42a5fc29a3290bcd14",
            "8ef0b2d19cd7480e925d3a42f1568e5d",
            "b7a5b3f118e0414ba7752f9d2d8c3acf",
            "24303f47b20545eb93540458487d8fd7",
            "4ce276aff0e9494bac328a24bf19162a",
            "47ece66d22bc4690b8af9f8941cde1a4",
            "baa22563affe49269c8b0529642c3b76",
            "e644618a2b3e4889b2be0dbe8c7f5edb",
            "62496961e9394ce0818a8e30802a5eef",
            "69be5aba9ff7421b8ff460536d10c0cb",
            "e8b25a0bc95149648449c3991c42bb94",
            "465433a14ac04c2db7fae313830b9fbc",
            "8fd24c38fdf0459580ebe76285f695ac",
            "9a6b680c4c424f06be473f8db5c9ff9c",
            "7f041d45543b45778e6b573c2881d59d",
            "0ca7653f6c3948e5b6ef8d22523a1248",
            "c74908c05c784cc788916fb3e0125c53",
            "8a377a361ff6484ba165ff6eabcef45f",
            "1a79fe64d12a42848dfd20479cfd464c",
            "c8ded981909f4000b6c7b95c2b9aa09e",
            "bf84f6675c4a43d2b2dd542956a1c478",
            "a57a849c07814324aa0fd43fb42c36d0",
            "1c646841638a45748dbdf233f36d04f2",
            "11948e50af8d4bb39405aa0a6595081d",
            "c759fe309edd4178b3e4afa49f11552c",
            "525faa561548477487d2793ed23553c4",
            "721f9a9f783f42c48fb26efe45791ef7",
            "e45bf0b54f844953896ce175463eb98c",
            "35ee881fcf8640dda6b5b34c050f5e85",
            "f4d81b3e3bd84b6ab546b008fe839f1e",
            "e9999ff49bf9403a86ce0b5c8c5112cb",
            "c003d2d7d9804cd58e84c3fb2a145897",
            "85abb4d0f7b24780b94428e2c1ca66fb",
            "f365010cf00d420a9f66f5440461c312",
            "76e225910f5f4671ac8fda0c491b4eee",
            "398137a70a354f89b032110e4b639814",
            "baada4fe31384a89aeb6984b4e777d8b",
            "c7953b272b3d4203b739a2cbc8b6ac8c",
            "aab2b39505ef4fb9964d0beb6baa0e3d",
            "256a8947793346139367e238d6f038c8",
            "e001141d2a6c44838459a063113a51dd",
            "90eb395decd14895a42f2294db4242fa",
            "d2973bf311b2478c911691e967deaf0b",
            "5a63fd5fd87947369649be01e6ce116c",
            "4d06a4b71b3d410ca8b4b7f80658df31",
            "2b7ee286f2b3499f9dc983f62940650c",
            "c3a1658adc0f4857b81ef8facabdd1f4",
            "b8ad8990c66e4b489fa8b609a6d50be7",
            "f9d365de116e40f5a78506606d650924",
            "3cf3373d1d62447ebb80de30797427fb",
            "dc21eba67a1442438e8239934cbb6559",
            "c921e107a3dc4562a3ab12e1eab96483",
            "f7d9b73a597b45659fdde9b048ce6a9d",
            "cab85fbe503d47929b37f77c360de790",
            "ec2570ece56f415f8305a72c482c1209",
            "bfa00ccbafc4416d96032d01e92fe47d",
            "142a3e01dd174efd807fc8592ce6df0d",
            "dc1a85fb3f394d7ba008083393035dd5",
            "efe1011d4d204a4d8b5667b55b8ea789",
            "e068e7c31444474d89b8f99f0d834435",
            "52951534a74d46159fe6b948867abc1d",
            "4342daab1a03414a991e5916467c400e",
            "688a56f1dae942039db3267ecc7dad30",
            "10dcdb326934489e9fa609d4d5e0e721",
            "5b23812a35af4f7081578b723d3e7495",
            "8c3a79e4cc3c4cbbb4720c9d6805ac68",
            "0df9b252174f41609f7ca7a0b01ac7a0",
            "b18bbf25ceb947f69c9b80d94d9f3a40",
            "cc57a32abcc4428dadb1cf7aad54682d",
            "349a1225967b4928b4bb3069acc4805b"
          ]
        },
        "id": "uJqulaQQY_XI",
        "outputId": "b8ca5a10-7aa7-4d7e-c249-c31fa0a09cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/895 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7801a0f8c6b45aabcc1370304fad4cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "configuration_decilm.py:   0%|          | 0.00/576 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c6e2c597c5042efbe0572cf090dbf30"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "version_check.py:   0%|          | 0.00/383 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90e5fe58413549859fe97a4be93e2eb6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/Deci/DeciLM-7B:\n",
            "- version_check.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)sformers_v4_35_2__configuration_llama.py:   0%|          | 0.00/9.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "998c69d5b6ff47978ad362e33717ba02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/Deci/DeciLM-7B:\n",
            "- transformers_v4_35_2__configuration_llama.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "A new version of the following files was downloaded from https://huggingface.co/Deci/DeciLM-7B:\n",
            "- configuration_decilm.py\n",
            "- version_check.py\n",
            "- transformers_v4_35_2__configuration_llama.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modeling_decilm.py:   0%|          | 0.00/14.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f667bd470484bfab2a5173209803971"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)ers_v4_35_2__modeling_attn_mask_utils.py:   0%|          | 0.00/10.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25e3ec78768f4c24b4805a310b765b8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/Deci/DeciLM-7B:\n",
            "- transformers_v4_35_2__modeling_attn_mask_utils.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "transformers_v4_35_2__modeling_llama.py:   0%|          | 0.00/56.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "931b01da7b624c1e83c30d668c72dac4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/Deci/DeciLM-7B:\n",
            "- transformers_v4_35_2__modeling_llama.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "A new version of the following files was downloaded from https://huggingface.co/Deci/DeciLM-7B:\n",
            "- modeling_decilm.py\n",
            "- transformers_v4_35_2__modeling_attn_mask_utils.py\n",
            "- transformers_v4_35_2__modeling_llama.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ce276aff0e9494bac328a24bf19162a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ca7653f6c3948e5b6ef8d22523a1248"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "721f9a9f783f42c48fb26efe45791ef7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7953b272b3d4203b739a2cbc8b6ac8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/4.18G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9d365de116e40f5a78506606d650924"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e068e7c31444474d89b8f99f0d834435"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizer"
      ],
      "metadata": {
        "id": "1-2sfo_49eMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "tokenizer.padding_side = \"right\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "debabdc0460d4ae9bbe4bffd4d90af55",
            "2c5f791949f74dbbb48624a6cdc96ee6",
            "6137120f84d643cd831967d09e9398f5",
            "6a0951c02d1641048de2a1f94def73ca",
            "f9d33f3b11034f73ae7d1b438d7ce47b",
            "02ca2f5e5c0240c3ad588bf62e86b624",
            "8d22e28ec9664f6cbadbc15b4a780f5a",
            "9f1733194a784cbda82dd8bc4a59cece",
            "53acf1d4cc86425f9fb7e85c5e425f37",
            "cbc1d8c7d8694b67970fd4ae02199c3a",
            "0f12d26d122840e98f1d98539a828b14",
            "5763c37ef1064c16a30644a821cbba8c",
            "8db0c9e36c35471d9a363a3655227c9a",
            "3fa81b4fc62c4f13b2db9a41af464130",
            "fd4e0b932d8f49ef926524a8a05ef082",
            "af024457dc64458fbef3fe70976e91a0",
            "8711b5d78b154183b800b530d9276ccd",
            "e7d12a1b370e4e9d8a17436c5a4dea98",
            "ba34e92d010d45a9b46d7b5ff146a091",
            "db9cff6ec9804eccbb8d6cc8db0aae2b",
            "ff24724d15c24e66857de05b1485117b",
            "0bad6a611e334c2cbd1eb0e79da91f31",
            "34baf4d85c2342108bfc0cf2b2cb115e",
            "8dc1362f74914ea0b519c7d27022854d",
            "2295e0a005ac4141a9ac2d2d3f2c97e8",
            "c7b9b77eb15e47f6b982127bbe6790db",
            "f11b5b00ad7b4486b05b783ee95b1aac",
            "d9cc20ba0d4b4fcaa20bced98affc063",
            "4f9a55d0960a423ebec6e52d19ccc755",
            "e973b6230c55410dbce6ed3e9074aa32",
            "71d86549ddee4d9a81196150c0ad5625",
            "713d88ac8aad4a83883b8a3eae583125",
            "ea7535b51e114fe2929fc2021100ac12",
            "a7e585622b9b418cb5f9723a33f6d200",
            "d1f3e0354362457ebd9270e6dbd61484",
            "04e74c421f434636b623cc0078f6764e",
            "1afe8dea704740ad8d2b7df293a607d1",
            "deca638442f845009ac07d9349ca6117",
            "01d5c407d9024506a21aca5662988e37",
            "63b4e7b430fc4477bffc54e4166d30aa",
            "d51480b6926944ffb968a5ea2bf6ceab",
            "b9d9e8af200c41fbbc49dc9421527e7b",
            "463ed660110446b69171eb1789988d1d",
            "e3fd8f5e1469464c803c4a0d129b3277"
          ]
        },
        "id": "7rwZ6snS9duc",
        "outputId": "a1b5ffed-a012-4c8f-ece3-9203cc229e94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "debabdc0460d4ae9bbe4bffd4d90af55"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5763c37ef1064c16a30644a821cbba8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34baf4d85c2342108bfc0cf2b2cb115e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7e585622b9b418cb5f9723a33f6d200"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset loader"
      ],
      "metadata": {
        "id": "K8UBYIVia88z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "bj0qGon_a_1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PTBXL_fintuning_dataset_path =  '/content/drive/MyDrive/finetuningdatasets/finetuningECG.csv'\n",
        "dataset = load_dataset(\"csv\", data_files= PTBXL_fintuning_dataset_path, split=\"train\")\n",
        "data = dataset.shuffle(seed=42)\n",
        "ECG_statements = data.train_test_split(test_size=0.1, seed=42)"
      ],
      "metadata": {
        "id": "sSAgl8hdPKKK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "c5561bf758c646e29744240230116be3",
            "1d7ad2c01e084e2aae35717959a41398",
            "f899447a560048e48975fdb16fa46e91",
            "945855dea50742cebec32a038db1c800",
            "fdf052c28e384514bfeb8f0959e0a2b4",
            "5c17f6a9aac44314be13b08c14833a58",
            "08933fef8dc7421f88b746448e1c1775",
            "a907572a3abc4fb295d5d69bd0d95090",
            "c291dfac9723479095e0cac42b089cdd",
            "f8ccbc3f45a34ecf8917a608f85340d9",
            "6a8c3502b9084e4c9d428c9da095ae4b"
          ]
        },
        "outputId": "af3ed0f8-5662-4bbd-b8fd-ed8fc9070f88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5561bf758c646e29744240230116be3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_construction(sample,modelname='DeciLM'):\n",
        "  if modelname == 'DeciLM':\n",
        "    prompt = \"\"\n",
        "    prompt += \"Generate a technical ECG report based on these Standard Communication Protocol for Computer-assisted Electrocardiography codes (SCP codes) (12 lead) \"\n",
        "    prompt += sample[\"input\"]\n",
        "    prompt += \"\\n\\n### Report: \\n \"\n",
        "    prompt += sample[\"output\"]\n",
        "    return {\"text\" : prompt}\n"
      ],
      "metadata": {
        "id": "VfCsT0ilbYiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ECG_statements_dataset = ECG_statements.map(prompt_construction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "14e84ab3b0a4493c8f56d699ca16770e",
            "a9cd6313c9c343cdac2bd580e0974730",
            "804b5c1ebd344883a6643f6cf763b090",
            "e1e061cf1e3f479d97bf97d6e65366c5",
            "effae7cfe84f4d07882b1c7025c081fc",
            "2cded81d9bbc4ce8b01d24663c157135",
            "4258032f1e264cf085d681dfe96c61d0",
            "e30c1ce08b024e369859421aa8241737",
            "d64b891d7568434bb6c1a7eee2ad4434",
            "b7557f91f250468ab0229a371dd9bc3c",
            "c55ce0ea4dda4623ba67097db824d8c5",
            "59b0f71ba2fc40bb9f9e0682edbab9e8",
            "81444bf8509047909910822c2d1422cf",
            "48a9d661d61a420d9e67ad1e276f92de",
            "f8fc988f7ed449a49ba6fdb1d6b9037f",
            "50d3c7df599f4af186ba6e9ee18ef8f4",
            "c660735e1299436aa956370ef3e3c097",
            "93797e090bb544c49144d0eb145d3f62",
            "5cff969f4340410f894eb8e182b433fc",
            "5da9a41e1f1e4122bd0b9add17bd8161",
            "a8377d56d2a8468d84a0804d02dc7382",
            "43ea176abe37485ba44adc7475e21e04"
          ]
        },
        "id": "HcEiTOH6o7DZ",
        "outputId": "c8ba4486-0748-423d-e9c1-135156a755ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/19247 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14e84ab3b0a4493c8f56d699ca16770e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2139 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59b0f71ba2fc40bb9f9e0682edbab9e8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ECG_statements_dataset['train'][42]['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsDanoVap7bk",
        "outputId": "7089d42a-c610-4c6c-a8b0-89d60e86f83c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Generate a technical ECG report based on these Standard Communication Protocol for Computer-assisted Electrocardiography codes (SCP codes) (12 lead) Description: ['left ventricular hypertrophy'] , SCP_codes: {'Superclass': {'NORM': 0, 'MI': 0, 'STTC': 0, 'CD': 0, 'HYP': 1}, 'Subclass': {'HYP': ['LVH'], 'MI': None, 'STTC': None, 'CD': None}}\\n\\n### Report: \\n sinus rhythm. voltages are high in chest leads suggesting lvh. borderline left axis deviation. Edit: LVH 35, Sokolow 3.6 (LVH 50)\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QLoRA configuration"
      ],
      "metadata": {
        "id": "l7gUgKznyDEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Website for config params:\n",
        "https://huggingface.co/docs/peft/package_reference/lora\n"
      ],
      "metadata": {
        "id": "dPXVUb3Hyxn3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Layers which we can apply LoRA to for training."
      ],
      "metadata": {
        "id": "kDH6Ig5K95QS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print([(n, type(m)) for n, m in model.named_modules()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9oK1Gvo0eum",
        "outputId": "cb3fb6cf-e3a9-4bca-a14f-43d961b92c07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMForCausalLM'>), ('model', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMModel'>), ('model.embed_tokens', <class 'torch.nn.modules.sparse.Embedding'>), ('model.layers', <class 'torch.nn.modules.container.ModuleList'>), ('model.layers.0', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.0.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.0.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.0.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.0.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.0.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.0.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.0.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.0.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.0.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.0.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.0.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.0.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.0.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.1', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.1.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.1.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.1.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.1.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.1.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.1.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.1.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.1.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.1.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.1.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.1.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.1.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.1.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.2', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.2.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.2.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.2.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.2.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.2.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.2.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.2.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.2.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.2.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.2.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.2.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.2.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.2.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.3', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.3.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.3.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.3.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.3.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.3.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.3.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.3.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.3.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.3.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.3.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.3.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.3.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.3.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.4', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.4.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.4.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.4.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.4.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.4.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.4.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.4.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.4.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.4.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.4.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.4.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.4.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.4.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.5', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.5.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.5.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.5.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.5.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.5.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.5.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.5.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.5.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.5.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.5.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.5.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.5.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.5.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.6', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.6.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.6.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.6.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.6.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.6.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.6.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.6.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.6.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.6.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.6.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.6.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.6.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.6.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.7', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.7.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.7.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.7.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.7.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.7.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.7.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.7.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.7.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.7.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.7.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.7.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.7.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.7.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.8', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.8.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.8.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.8.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.8.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.8.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.8.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.8.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.8.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.8.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.8.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.8.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.8.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.8.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.9', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.9.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.9.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.9.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.9.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.9.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.9.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.9.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.9.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.9.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.9.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.9.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.9.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.9.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.10', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.10.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.10.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.10.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.10.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.10.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.10.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.10.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.10.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.10.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.10.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.10.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.10.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.10.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.11', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.11.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.11.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.11.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.11.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.11.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.11.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.11.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.11.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.11.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.11.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.11.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.11.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.11.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.12', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.12.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.12.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.12.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.12.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.12.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.12.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.12.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.12.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.12.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.12.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.12.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.12.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.12.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.13', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.13.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.13.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.13.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.13.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.13.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.13.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.13.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.13.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.13.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.13.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.13.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.13.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.13.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.14', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.14.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.14.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.14.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.14.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.14.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.14.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.14.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.14.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.14.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.14.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.14.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.14.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.14.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.15', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.15.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.15.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.15.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.15.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.15.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.15.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.15.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.15.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.15.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.15.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.15.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.15.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.15.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.16', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.16.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.16.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.16.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.16.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.16.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.16.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.16.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.16.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.16.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.16.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.16.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.16.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.16.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.17', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.17.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.17.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.17.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.17.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.17.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.17.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.17.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.17.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.17.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.17.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.17.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.17.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.17.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.18', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.18.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.18.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.18.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.18.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.18.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.18.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.18.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.18.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.18.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.18.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.18.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.18.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.18.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.19', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.19.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.19.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.19.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.19.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.19.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.19.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.19.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.19.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.19.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.19.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.19.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.19.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.19.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.20', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.20.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.20.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.20.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.20.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.20.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.20.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.20.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.20.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.20.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.20.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.20.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.20.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.20.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.21', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.21.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.21.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.21.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.21.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.21.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.21.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.21.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.21.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.21.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.21.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.21.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.21.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.21.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.22', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.22.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.22.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.22.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.22.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.22.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.22.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.22.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.22.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.22.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.22.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.22.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.22.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.22.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.23', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.23.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.23.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.23.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.23.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.23.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.23.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.23.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.23.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.23.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.23.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.23.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.23.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.23.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.24', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.24.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.24.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.24.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.24.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.24.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.24.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.24.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.24.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.24.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.24.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.24.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.24.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.24.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.25', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.25.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.25.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.25.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.25.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.25.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.25.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.25.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.25.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.25.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.25.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.25.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.25.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.25.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.26', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.26.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.26.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.26.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.26.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.26.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.26.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.26.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.26.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.26.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.26.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.26.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.26.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.26.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.27', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.27.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.27.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.27.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.27.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.27.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.27.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.27.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.27.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.27.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.27.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.27.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.27.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.27.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.28', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.28.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.28.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.28.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.28.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.28.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.28.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.28.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.28.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.28.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.28.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.28.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.28.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.28.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.29', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.29.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.29.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.29.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.29.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.29.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.29.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.29.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.29.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.29.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.29.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.29.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.29.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.29.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.30', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.30.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.30.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.30.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.30.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.30.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.30.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.30.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.30.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.30.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.30.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.30.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.30.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.30.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.31', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMDecoderLayer'>), ('model.layers.31.self_attn', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm.DeciLMAttention'>), ('model.layers.31.self_attn.q_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.31.self_attn.k_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.31.self_attn.v_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.31.self_attn.o_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.31.self_attn.rotary_emb', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding'>), ('model.layers.31.mlp', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaMLP'>), ('model.layers.31.mlp.gate_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.31.mlp.up_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.31.mlp.down_proj', <class 'bitsandbytes.nn.modules.Linear4bit'>), ('model.layers.31.mlp.act_fn', <class 'transformers.activations.SiLUActivation'>), ('model.layers.31.input_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.layers.31.post_attention_layernorm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('model.norm', <class 'transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.transformers_v4_35_2__modeling_llama.LlamaRMSNorm'>), ('lm_head', <class 'torch.nn.modules.linear.Linear'>)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MLP**\n",
        "1.   up_proj\n",
        "2.   gate_proj\n",
        "3.   down_proj\n",
        "\n",
        "**Attention**\n",
        "1.   q_proj\n",
        "2.   k_proj\n",
        "3.   v_proj\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "E2TAaJA93QnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import peft\n",
        "\n",
        "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=256,\n",
        "    lora_alpha=512,\n",
        "    lora_dropout=0.1,\n",
        "    target_modules = [\"gate_proj\", \"down_proj\", \"up_proj\",\"q_proj\", \"v_proj\",\"k_proj\",],\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")"
      ],
      "metadata": {
        "id": "v1ksiDwdrL6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepping model for quyantization"
      ],
      "metadata": {
        "id": "jSlJgN0i-p9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decilm = prepare_model_for_kbit_training(model)\n",
        "decilm = get_peft_model(decilm, lora_config)"
      ],
      "metadata": {
        "id": "fS9TJAdax8pV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training config"
      ],
      "metadata": {
        "id": "CBQC_4j0-y4O"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7lQ5miEg4Xxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "        output_dir=DeciLora,\n",
        "        evaluation_strategy=\"steps\",\n",
        "        do_eval=True,\n",
        "        auto_find_batch_size=True,\n",
        "        log_level=\"debug\",\n",
        "        optim=\"paged_adamw_8bit\",\n",
        "        save_steps=25,\n",
        "        logging_steps=100,\n",
        "        learning_rate=2e-4,\n",
        "        weight_decay=0.01,\n",
        "        max_steps=len(ECG_statements_dataset['train']),\n",
        "        warmup_steps=150,\n",
        "        fp16=True,\n",
        "        gradient_checkpointing=True,\n",
        "        max_grad_norm=0.3,\n",
        "        lr_scheduler_type=\"reduce_lr_on_plateau\",\n",
        ")"
      ],
      "metadata": {
        "id": "J95MqbzlyA4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=decilm,\n",
        "    args=training_args,\n",
        "    peft_config=lora_config,\n",
        "    tokenizer=tokenizer,\n",
        "    dataset_text_field='text',\n",
        "    train_dataset=ECG_statements_dataset['train'],\n",
        "    eval_dataset=ECG_statements_dataset['test'],\n",
        "    max_seq_length=4096,\n",
        "    dataset_num_proc=os.cpu_count(),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "825f3b6c603a4354aafdb7e95edbea77",
            "e1fd3b4ddbfc4a98ae6433b5c1e85c5a",
            "44e085c417164432be6677d5e960cae1",
            "d466a93ed09e4ff48ec57929cb4610ef",
            "8b8e9cda9ffd4477be350e1da0a4c750",
            "46090990ac3046b3b193c5c5400f9952",
            "579a14aed0c7455098180d3ce8786131",
            "05b65c58492449c9812dc3386497aa71",
            "f29d8d0f8cf24a40baffcabee56bb9c2",
            "431784b7fb3f4dc2b22d182b81e0785e",
            "0f43f4cf4497498fa6ff9f42e810d1e5",
            "c99f2117cfe8431497ca23936f40e9aa",
            "ce6e57351b25474795e372f524ba418f",
            "5ecfd83a338842c6b2c6afe4c13d8b11",
            "20743cc02cf54d809ec9d88c8630afde",
            "cfcfbfa797ba4ac3afdc29b65a23aa4c",
            "3be65f01365b46d9ab56bd984352d596",
            "6c6df6e9f35f4994a011b875f53da444",
            "c1a86edd9cd04afbaa64aadc26a7a6ed",
            "d82e8cf634704036980deedbc9c3ce3b",
            "4e421d04415941638873cc624e7cefaa",
            "682a96a8a4524a3789e9b2d53da90dfb"
          ]
        },
        "id": "X-heK8NnHSDR",
        "outputId": "5dc319e4-1acd-4135-98dc-d841f246060c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=8):   0%|          | 0/19247 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "825f3b6c603a4354aafdb7e95edbea77"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=8):   0%|          | 0/2139 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c99f2117cfe8431497ca23936f40e9aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n",
            "Using auto half precision backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ASSuoUVzIWBE",
        "outputId": "c3b7df86-3a03-4582-9d76-c89bf0d69645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Currently training with a batch size of: 8\n",
            "***** Running training *****\n",
            "  Num examples = 19,247\n",
            "  Num Epochs = 8\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 19,247\n",
            "  Number of trainable parameters = 591,593,472\n",
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "WARNING:transformers_modules.Deci.DeciLM-7B.cdd1aef103a52ac458dee200ad0661c967dd0e63.modeling_decilm:`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='976' max='19247' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  976/19247 1:08:04 < 21:16:59, 0.24 it/s, Epoch 0.41/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.858500</td>\n",
              "      <td>0.392141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.358600</td>\n",
              "      <td>0.292164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>3.536800</td>\n",
              "      <td>3.249036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>2.417900</td>\n",
              "      <td>1.945753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.345500</td>\n",
              "      <td>0.961491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.865100</td>\n",
              "      <td>0.915472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.773000</td>\n",
              "      <td>0.698359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.759300</td>\n",
              "      <td>0.560320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.526100</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-25\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-25/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-25/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-50\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-50/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-50/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-75\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-75/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-75/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2139\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-100\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-100/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-100/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-125\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-125/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-125/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-150\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-150/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-150/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-175\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-175/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-175/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2139\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-200\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-200/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-200/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-225\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-225/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-225/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-250\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-250/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-250/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-275\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-275/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-275/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2139\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-300\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-300/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-300/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-325\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-325/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-325/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-350\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-350/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-350/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-375\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-375/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-375/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2139\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-400\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-400/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-400/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-425\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-425/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-425/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-450\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-450/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-450/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-475\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-475/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-475/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2139\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-500\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-500/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-525\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-525/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-525/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-550\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-550/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-550/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-575\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-575/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-575/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2139\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-600\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-600/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-600/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-625\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-625/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-625/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-650\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-650/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-650/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-675\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-675/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-675/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2139\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-700\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-700/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-700/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-725\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-725/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-725/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-750\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-750/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-750/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-775\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-775/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-775/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2139\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-800\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-800/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-800/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-825\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-825/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-825/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-850\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-850/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-850/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-875\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-875/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-875/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2139\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-900\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-900/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-900/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-925\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-925/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-925/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-950\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer config file saved in DeciLora_finetuned_checkpoints/checkpoint-950/tokenizer_config.json\n",
            "Special tokens file saved in DeciLora_finetuned_checkpoints/checkpoint-950/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to DeciLora_finetuned_checkpoints/checkpoint-975\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Deci--DeciLM-7B/snapshots/cdd1aef103a52ac458dee200ad0661c967dd0e63/config.json\n",
            "Model config DeciLMConfig {\n",
            "  \"architectures\": [\n",
            "    \"DeciLMForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Deci/DeciLM-7B--configuration_decilm.DeciLMConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Deci/DeciLM-7B--modeling_decilm.DeciLMForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"deci\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"num_key_value_heads_per_layer\": [\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    4,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    1,\n",
            "    4\n",
            "  ],\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 2.0,\n",
            "    \"type\": \"dynamic\"\n",
            "  },\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"LlamaTokenizer\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"use_bfloat16\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SafetensorError",
          "evalue": "Error while serializing: IoError(Os { code: 28, kind: StorageFull, message: \"No space left on device\" })",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSafetensorError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trl_activate_neftune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# After training we make sure to retrieve back the original forward pass method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1555\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1556\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/memory.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No executable batch size found, reached zero.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_reduce_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1920\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1922\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1923\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1924\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2282\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2283\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2348\u001b[0m         \u001b[0mrun_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_output_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2349\u001b[0m         \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2350\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_internal_call\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_deepspeed_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2352\u001b[0m             \u001b[0;31m# under zero3 model file itself doesn't get saved since it's bogus! Unless deepspeed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2843\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0;31m# Push to the Hub when `save_model` is called by the user.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   2899\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWEIGHTS_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2900\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2901\u001b[0;31m             self.model.save_pretrained(\n\u001b[0m\u001b[1;32m   2902\u001b[0m                 \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_serialization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_safetensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2903\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36msave_pretrained\u001b[0;34m(self, save_directory, safe_serialization, selected_adapters, save_embedding_layers, is_main_process, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m                         \u001b[0moutput_state_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshared_tensor_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_state_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshared_tensor_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m                 safe_save_file(\n\u001b[0m\u001b[1;32m    249\u001b[0m                     \u001b[0moutput_state_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAFETENSORS_WEIGHTS_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/safetensors/torch.py\u001b[0m in \u001b[0;36msave_file\u001b[0;34m(tensors, filename, metadata)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \"\"\"\n\u001b[0;32m--> 281\u001b[0;31m     \u001b[0mserialize_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSafetensorError\u001b[0m: Error while serializing: IoError(Os { code: 28, kind: StorageFull, message: \"No space left on device\" })"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model()"
      ],
      "metadata": {
        "id": "NwwCe5aLIf3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RAG"
      ],
      "metadata": {
        "id": "0WVaypW-z6b0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
        "\n",
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext"
      ],
      "metadata": {
        "id": "1I1cTzkhYw6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader(\"/content/RAG_documents/\").load_data()"
      ],
      "metadata": {
        "id": "ewhB9u1HY4pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from llama_index.llms import LlamaCPP\n",
        "from llama_index.llms.llama_utils import messages_to_prompt, completion_to_prompt\n",
        "llm = LlamaCPP(\n",
        "    model_url='https://huggingface.co/TristanCarlisle/Mistral-7B-ECGfinetunedmodel.gguf',\n",
        "    model_path=None,\n",
        "    temperature=0.1,\n",
        "    max_new_tokens=256,\n",
        "    context_window=3900,\n",
        "    generate_kwargs={},\n",
        "    model_kwargs={\"n_gpu_layers\": -1},\n",
        "    messages_to_prompt=messages_to_prompt,\n",
        "    completion_to_prompt=completion_to_prompt,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "_A8tV3F30Qnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install sentence-transformers\n",
        "!pip -q install langchain"
      ],
      "metadata": {
        "id": "P9lcTKey0mX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from llama_index import ServiceContext\n",
        "\n",
        "embed_model = HuggingFaceEmbeddings(model_name=\"thenlper/gte-large\")"
      ],
      "metadata": {
        "id": "uQfUd-p80pHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "service_context = ServiceContext.from_defaults(\n",
        "    chunk_size=256,\n",
        "    llm=llm,\n",
        "    embed_model=embed_model\n",
        ")"
      ],
      "metadata": {
        "id": "tEYUwH4b0qpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
        "index.storage_context.persist(persist_dir=\"./storage\")\n",
        "query_engine = index.as_query_engine(streaming=True, similarity_top_k=1, service_context=service_context)\n",
        "response_stream = query_engine.query(f\"Describe this term Left ventricular hypertophy and its ECG presentation in lead I\")\n",
        "response_stream.print_response_stream()"
      ],
      "metadata": {
        "id": "hvOwzeft0riu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}